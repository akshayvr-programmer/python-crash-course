{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section B: Computer Vision.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfd2kry/ZsIBhHzTNfW0lw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshayvr-programmer/python-crash-course/blob/main/Section_B_Computer_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB5QwVuSoSaN"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Hi and welcome to Section B of the python Crash Course. This is a continuation of the earlier course. Please read that before starting off with this one. The link is given down below:\n",
        "\n",
        " https://github.com/akshayvr-programmer/python-crash-course \n",
        "\n",
        " In this section we'll be learning about computervision. We'll mainly be using a library of computervision in Python known as opencv. For a part of this section we'll have to use Pycharm IDE. If you haven't installed pycharm please go to : https://www.jetbrains.com/pycharm/\n",
        " For installation of python please go to : https://www.python.org/downloads/\n",
        " While installing Python please check the Add to PATH box. \n",
        "\n",
        " The contents of the course are:\n",
        "1. Introduction to Computervision\n",
        "\n",
        "\n",
        "2. Computervision Libraries in Python\n",
        "3. Introduction to Haar Cascades and creating Haar-Cascades\n",
        "\n",
        "4. Various detection apps such as: a) Face detection b) Pedestrian and Vehicle detection c) Sunglasses detection d) Smile detection\n",
        "\n",
        "5. We'll also be learning how to access various algorithms of computervision in github.\n",
        "\n",
        "Before starting with the course, there is a shell script that you'll need to run in order to install opencv on your computer.\n",
        "\n",
        "If you're using windows, go to cmd and type the following command and hit enter:\n",
        " \n",
        " pip install opencv-python\n",
        " I would recommend writing all the code that I write here on pycharm and trying it out.\n",
        "\n",
        " I hope that you'll have a lot of fun in the course! It is a fun one.\n",
        "\n",
        " Happy Coding!\n",
        " \n",
        " Akshay V.R."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Fvj0p4GriUw"
      },
      "source": [
        "#Section B: 1. Introduction to Computervision\n",
        "\n",
        "Have you ever seen self driving cars and wondered how they are able to detect vehicles and pedestrians infront of them so easily. The answer to the question is simple they all use computervision. All the self driving cars and robots use computervision. Computervision is a domain of AI (Artificial Intelligence).\n",
        "It is defined as an interdisciplinary scientific field that deals with how computers can gain high level understanding  of objects from digital images or videos.  \n",
        "\n",
        "#Section B: 2. \n",
        "The main computervision library that we'll be talking about in this course is opencv.  There are various other computervision libraries such as :\n",
        "\n",
        "1. PyTorch\n",
        "2. Tensorflow\n",
        "3. Theano\n",
        "4. Dlib\n",
        "5. Accord.NET\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxhMpbaes8fi"
      },
      "source": [
        "#Section B: 3 \n",
        "You may be wondering, how does Python recognise all these objects all by itself, it must be having some algorithm in place. This algorithm is known as a haar cascade. It is an xml document that is very very important. To create a Haar Cascade You will need two sets of images: 1. Positive images 2. Negative images. Then, you run these images through a GUI Cascade Trainer. \n",
        "\n",
        "# The Logic behind Cascade Classifiers\n",
        "\n",
        "Haar Cascade is a machine learning object detection algorithm used to identify objects in an image or video and based on the concept of ​​ features proposed by Paul Viola and Michael Jones in their paper \"Rapid Object Detection using a Boosted Cascade of Simple Features\" in 2001.\n",
        "\n",
        "It is a machine learning approach from which a cascade trainer learns from a lot of positive and negative image data sets.\n",
        "\n",
        "The algorithm has four stages:\n",
        "\n",
        "1. Haar Feature Selection\n",
        "2. Creating  Integral Images\n",
        "3. Adaboost Training\n",
        "4. Cascading Classifiers\n",
        "\n",
        "# Haar Feature Selection\n",
        "The Haar Feature Selection consists of various differently sized rectangles that sums up the pixel intensities and calculates the difference between these sums.\n",
        "\n",
        "\n",
        "# Creating Integral Images:\n",
        "Integral Images can be used to make this process super fast! All the pixel intensities are integrated. This is a faster mathematical approach. \n",
        "\n",
        "# Adaboost Training:\n",
        "\n",
        "Out of the hundreds of images that are used and out of millions of  features, the most evident of these features are selected. This happens through adaboost training. The adaboost trainer creates vector files. These are the files that differentiate between fast learning images vs. weak learners. Once this is done in the backend, the algorithm is created.\n",
        "\n",
        "# Cascading Classifier\n",
        "Once all of  this is done in the backend, the algorithm is created.\n",
        "\n",
        "\n",
        "# For additional Info:\n",
        "To learn more about haar cascades please visit:  http://www.willberger.org/cascade-haar-explained/#:~:text=A%20Haar%E2%80%8B%20feature%20considers,to%20make%20this%20super%20fast.\n",
        "\n",
        "# Creating your own Cascade Classifier:\n",
        "1. To understand how haar cascades are made, you can visit: https://www.cs.auckland.ac.nz/~m.rezaei/Tutorials/Creating_a_Cascade_of_Haar-Like_Classifiers_Step_by_Step.pdf\n",
        "\n",
        "There is a step by step explanation to the entire process. But remember, creating cascade classifiers is not an easy job, it is very time consuming. Using the above mentioned method, it might as well take way over 6 hours to create a classifier algorithm. \n",
        "\n",
        "2. Another method of doing the same in a much faster way is:\n",
        "a) Go to the following website: http://amin-ahmadi.com/cascade-trainer-gui/, scroll down to the bottom and click on the download button and install the GUI Cascade Trainer App.\n",
        "b) Create a database of negative and positive images in a folder on your computer. Name the folder of negative images as n and the folder of positive images as p.\n",
        "c) The steps of how to use the software is mentioned in the website. There is a step-by-step explanation to everything. \n",
        "\n",
        "\n",
        "For now, while creating our face detection and other detection apps, we'll be using GitHub to get our cascade classifiers.\n",
        "\n",
        "Let's now shift to the pycharm IDE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgSd3BWFlp9k"
      },
      "source": [
        "I'll write the code here, you can copy the same in pycharm.\n",
        "Let's begin by importing the computervision library. The Haar Cascade File will be provided in  github. I'll be posting the code below. Try and copy the code and post it on notepad. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VEn4-pAozDN"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XUPYLcPo165"
      },
      "source": [
        "Now, let's make cv2 read the cascade classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMqVA3Plo-t7"
      },
      "source": [
        "algo = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcjDSfJqqIrD"
      },
      "source": [
        "Now, we can capture the video of our face."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jClZ4UkXqNdj",
        "outputId": "a38a36c6-b541-4eb2-9114-23b10fcd8ab0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "webcam = cv2.VideoCapture(0)\n",
        "cv2.waitKey(2000)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkX8HUwnqmz0"
      },
      "source": [
        "We'll have to create a while loop so that all the code that we write ahead is constantly looped.\n",
        "After capturing the video, we'll need to store the pixel data in two variables. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIkaPOw4qmFy"
      },
      "source": [
        "while True:\n",
        "succesful_frame_read, frame = webcam.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufD0IMlwrtH9"
      },
      "source": [
        " In the while loop, we'll have to convert the videoCapture into greyscale. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_ll1LgwsVr-"
      },
      "source": [
        "greyscale_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YMDHsRyswSQ"
      },
      "source": [
        "After converting the image to grayscale, we have to get the coordinates of the face using the cascade classifier algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGI3noKjtFmh"
      },
      "source": [
        "coordinates = cv2.detectMultiScale(greyscale_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG7TnEDAtZnW"
      },
      "source": [
        "Once we have the coordinates, we can create a loop which constantly detects the face and draws a rectangle over the face."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybmvOQMCtptN"
      },
      "source": [
        "for (x, y, w, h) in coordinates:\n",
        "  cv2.rectangle((x, y), (x+y, w+h), (255, 0, 0), 2) # (x, y) - coordinates, (x+w, y+h) - Rectangle function, (255, 0, 0) - Defines the color, 2 - width of the rectangle\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-KoX5MDuYPH"
      },
      "source": [
        "Now, let's show the final video with the face detection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfkVDDSvuqPz"
      },
      "source": [
        "cv2.imshow('face', frame)\n",
        "cv2.waitkey(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2YvXP4_u1MU"
      },
      "source": [
        "Final Code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-zV0JNau2ug"
      },
      "source": [
        "import cv2\n",
        "algo = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "webcam = cv2.VideoCapture(0)\n",
        "cv2.waitKey(2000)\n",
        "while True:\n",
        "  succesful_frame_read, frame = webcam.read()\n",
        "  gray_Scale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "  coordinates = cv2.detectMultiScale(greyscale_image)\n",
        "  for (x, y, w, h) in coordinates:\n",
        "    cv2.rectangle((x, y), (x+y, w+h), (255, 0, 0), 2)\n",
        "    cv2.imshow('face', frame)\n",
        "    cv2.waitkey(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCUwprnlvtFX"
      },
      "source": [
        "Post this code on Pycharm or VS Code and check the Output. \n",
        "You can also clone the project from my repository: https://github.com/Axotronics/Python-Face-Detection\n",
        "\n",
        "The xml files and python code is provided here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E7uAEBIwJtQ"
      },
      "source": [
        "# Challenge Time!\n",
        "\n",
        "I want all  the readers to build a python app that draws a blue rectangle on a pedestrian and a red rectangle on a car. The xml files can be cloned from my repository: https://github.com/Axotronics/Car-and-pedestrian-detection\n",
        "\n",
        "Try Writing the code by yourself. If you get stuck, you can refer the main.py file. Once you have understood the concept you can apply it for other detections too. Open CV is a very useful tool for object detection. Hope this was very informative!\n",
        "\n",
        "This is the end of Section B.  For other haar cascade files you can visit this repository: https://github.com/anaustinbeing/haar-cascade-files.\n",
        "\n",
        "\n",
        "Thanks a lot for reading!\n",
        "\n",
        "See you in Section C!\n",
        "\n",
        "Happy Coding!\n",
        "\n",
        "Akshay V.R."
      ]
    }
  ]
}